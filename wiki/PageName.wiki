#summary One-sentence summary of this page.
#labels Phase-Design,Phase-Requirements

简述项目实施步骤。

= Introduction =

   为使项目参与者能快速了解项目的阶段目标、最终目标，从而根据自己的兴趣、能力以及学习的需求，有选择的参与不同阶段的项目实施，从而使项目和个人达到双赢。

   根据项目的硬件特征，围绕上、下位机分为两条线展开。

= Details =

== 一、下位机（STM32）部分实施路线图 ==

*Step1：*

   基于CMSIS和ST的STM32F10x Standard Peripherals Library ，在无操作系统下编程，实现如下功能：

       # 电机驱动 —— 控制电机正、反转、调速、刹车、惰行
       # 码盘采样 —— 采集车轮转动信息，控制行走距离和速度
       # 电机电流检测 —— 测量电机工作电流，判断电机运动状态及转速
       # 电池电压测量 —— 辅助电流测量，计算转速，得到快速的速度反馈。同时兼做为电池剩余电量监测，根据电压判断是否要充电，根据电机工作和不工作之间的电压差计算电池内阻变化，从而判断电池是否需要更换。
       # 充电电源检测 —— 检测充电电压，判断目前是否处在充电状态
       # 传感器扩展 —— 能扩充一些后续学习中所必须增加的传感器
       # 和上位机通讯 —— 接受上位机控制，上传小车及传感器信息
       # 无线终端链路 —— 这是一个为上位机服务的功能，因为在Linux下编程，需要用串口和PC相连，使用“超级终端”作为人机界面。而小车是移动的，用线缆很不方便，故设计一个全双工的无线链路，实现PC终端的无线操作。此无线链路由下位机控制无线模块实现。
       # 实时时钟 —— 这是一个辅助功能，为做一个自主生存的机器人所预备。

    可以分开、独立实现，或几个相关功能组合实现，不要求同时实现全部功能。

    在无操作系统下编程实现上述功能，主要目的是为降低实现难度，为调试提供方便。因为如果直接在OS下实现，要考虑的因素和调试的难度都会大大增加。

    每项功能的具体要求见设计任务书。

*Step2：*

   建立uCOSII 程序框架，将Step1中所实现的功能逐一移植到操作系统下，逐步实现所有功能。

   Step1 和Step2 可以交叉进行，但要有总体规划，特别是一些实时性要求高的功能，在规划任务优先级时要提前有所考虑。

*Step3：*

   根据上位机需求，在Step2基础上，增加与上位机相应的交互接口，以实现上、下位机交互。

    交互接口按两个角度设计：

    第一：以上位机（ARM9）为主，下位机为从，下位机接受上位机控制，完成所需的功能。

    第二：以下位机（STM32）为主，上位机为从，由下位机控制小车的行动，上位机只相当于一个高级的智能图象传感器，或提供一个Wifi网络通道。

    _这个要求对于上位机同样有效。_

    之所以提出此要求，是考虑到学习者切入的便利。

    有些人侧重于硬件控制，即可忽略上位机编程，将上位机当成一个传感器。

    而那些侧重于嵌入式软件学习的则可以忽略下位机编程，将下位机作为一个执行机构。

== 二、上位机（ARM9）部分实施路线图==

    目前所有功能基于Linux实现，使用FriendlyARM提供的最新Linux操作系统。因为小车没有LCD显示器，建议不使用Qt，以提高速度，降低功耗。

    首先应裁减系统，使之符合小车的要求，并消除不需要的部分，降低系统开销。

    小车需要的资源：
        # CMOS摄像头
        # 串口（COM0、COM2）
        # USB Dev （从设备）
        # USB Host （主设备）
        # USB口 U盘
        # USB口 Wifi 模块
        # USB口通用摄像头（作为备用）

    其它设备暂不需要。

*Step1：*

   实现CAM130 摄像头图像采集，并能过通过串口控制拍照，将jpg或bmp格式的照片回传到PC机；同时在PC上编写相应的程序辅助控制和显示照片。

*Step2：*

   根据图像识别需求，实现定时图像捕获，并将图像格式转换为图像识别所需的格式（如YUV422）。同时能将捕获的图像传送至PC，利用PC 上的丰富资源实现图像识别，以验证算法和优化效率。

   识别从对特定色块的捕获开始，逐步实现：

   根据已知的色块信息（大小、形状），结合小车行走一定距离后色块图像的变化，判断色块的位置和距离，为导航提供可能。

*Step3：*

   将PC上实现的图像识别功能（Step2）移植到小车的上位机上，实现对特定物体（色块）的跟踪。

*Step4：*

   逐步优化识别的能力，实现图像导航，即对已知颜色的障碍物实现绕行，到达指定的目标（已知颜色），所有障碍和目标都以色块的颜色和形状（大小）为特征。

*Step5：*

   构建一些项目（如1对1 足球），整合实现的上述基础功能，实现之，从而检验所实现的功能是否可靠，同时根据出现的问题改进之。

   上述步骤将随着需求的增加而不断循环，使图像识别功能不断完善，让小车的“眼睛”更加“明亮”。

*Step6：*

   完成Wifi卡驱动，构建一个Linux下的Server，实现远程操控。

   上述功能实现时，均考虑与下位机的交互接口，按照前述两个角度设计。

== 三、结语==

   上述只是初步构思，在项目实施过程中将逐步完善。

                                            ——————————

2010年8月26日星期四